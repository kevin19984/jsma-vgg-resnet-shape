{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "large_LeNet_jsma.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "br0hfa3NWtMD"
      },
      "source": [
        "!pip install cleverhans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp5TsTAZYbpi"
      },
      "source": [
        "%tensorflow_version 1.5\n",
        "import tensorflow as tf\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omdq849MWzeY"
      },
      "source": [
        "# pylint: disable=missing-docstring\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import logging\n",
        "import numpy as np\n",
        "from six.moves import xrange\n",
        "\n",
        "from cleverhans.attacks import SaliencyMapMethod\n",
        "from tensorflow.python.platform import flags\n",
        "from cleverhans.dataset import MNIST\n",
        "from cleverhans.loss import CrossEntropy\n",
        "from cleverhans.utils import other_classes, set_log_level\n",
        "from cleverhans.utils import pair_visual, grid_visual, AccuracyReport\n",
        "from cleverhans.utils_tf import model_eval, model_argmax\n",
        "from cleverhans.train import train\n",
        "\n",
        "import functools\n",
        "\n",
        "from cleverhans import initializers\n",
        "from cleverhans.model import Model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSW1PggoX0vJ"
      },
      "source": [
        "class myLeNet(Model):\n",
        "  def __init__(self, scope, nb_classes, nb_filters, iteration, **kwargs):\n",
        "    del kwargs\n",
        "    Model.__init__(self, scope, nb_classes, locals())\n",
        "    self.nb_filters = nb_filters\n",
        "    self.iteration = iteration\n",
        "    # Do a dummy run of fprop to make sure the variables are created from\n",
        "    # the start\n",
        "    self.fprop(tf.placeholder(tf.float32, [128, 28, 28, 1]))\n",
        "    # Put a reference to the params in self so that the params get pickled\n",
        "    self.params = self.get_params()\n",
        "\n",
        "  def fprop(self, x, **kwargs):\n",
        "    del kwargs\n",
        "    my_conv = functools.partial(\n",
        "        tf.layers.conv2d, activation='tanh',\n",
        "        kernel_initializer=initializers.HeReLuNormalInitializer)\n",
        "    with tf.variable_scope(self.scope, reuse=tf.AUTO_REUSE):\n",
        "      for _ in range(self.iteration):\n",
        "        x = my_conv(x, 6, 5, strides=1, padding='same')\n",
        "        x = tf.compat.v1.keras.layers.MaxPool2D((2, 2), strides = (1, 1), padding='same')(x)\n",
        "      x = my_conv(x, 6, 5, strides=1, padding='valid')\n",
        "      x = tf.compat.v1.keras.layers.AveragePooling2D((2, 2), strides = (2, 2))(x)\n",
        "      x = my_conv(x, 16, 5, strides=1, padding='valid')\n",
        "      x = tf.compat.v1.keras.layers.AveragePooling2D((2, 2), strides = (2, 2))(x)\n",
        "      x = tf.layers.flatten(x)\n",
        "      x = tf.layers.dense(x, 120, activation='tanh')\n",
        "      x = tf.layers.dense(x, 84, activation='tanh')\n",
        "      logits = tf.layers.dense(x, self.nb_classes, activation='tanh', kernel_initializer=initializers.HeReLuNormalInitializer)\n",
        "      return {self.O_LOGITS: logits,\n",
        "              self.O_PROBS: tf.nn.softmax(logits=logits)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bZzev2tYrjx"
      },
      "source": [
        "FLAGS = flags.FLAGS\n",
        "\n",
        "VIZ_ENABLED = True\n",
        "NB_EPOCHS = 6\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = .001\n",
        "SOURCE_SAMPLES = 10\n",
        "\n",
        "\n",
        "def mnist_tutorial_jsma(train_start=0, train_end=60000, test_start=0,\n",
        "                        test_end=10000, viz_enabled=VIZ_ENABLED,\n",
        "                        nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE,\n",
        "                        source_samples=SOURCE_SAMPLES,\n",
        "                        learning_rate=LEARNING_RATE):\n",
        "  \"\"\"\n",
        "  MNIST tutorial for the Jacobian-based saliency map approach (JSMA)\n",
        "  :param train_start: index of first training set example\n",
        "  :param train_end: index of last training set example\n",
        "  :param test_start: index of first test set example\n",
        "  :param test_end: index of last test set example\n",
        "  :param viz_enabled: (boolean) activate plots of adversarial examples\n",
        "  :param nb_epochs: number of epochs to train model\n",
        "  :param batch_size: size of training batches\n",
        "  :param nb_classes: number of output classes\n",
        "  :param source_samples: number of test inputs to attack\n",
        "  :param learning_rate: learning rate for training\n",
        "  :return: an AccuracyReport object\n",
        "  \"\"\"\n",
        "  # Object used to keep track of (and return) key accuracies\n",
        "  report = AccuracyReport()\n",
        "\n",
        "  # Set TF random seed to improve reproducibility\n",
        "  tf.set_random_seed(1234)\n",
        "\n",
        "  # Create TF session and set as Keras backend session\n",
        "  sess = tf.Session()\n",
        "  print(\"Created TensorFlow session.\")\n",
        "\n",
        "  set_log_level(logging.DEBUG)\n",
        "\n",
        "  # Get MNIST test data\n",
        "  mnist = MNIST(train_start=train_start, train_end=train_end,\n",
        "                test_start=test_start, test_end=test_end)\n",
        "  x_train, y_train = mnist.get_set('train')\n",
        "  x_test, y_test = mnist.get_set('test')\n",
        "  \n",
        "  # Obtain Image Parameters\n",
        "  img_rows, img_cols, nchannels = x_train.shape[1:4]\n",
        "  nb_classes = y_train.shape[1]\n",
        "\n",
        "  # Define input TF placeholder\n",
        "  x = tf.placeholder(tf.float32, shape=(None, img_rows, img_cols,\n",
        "                                        nchannels))\n",
        "  y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
        "\n",
        "  nb_filters = 64\n",
        "  # Define TF model graph\n",
        "  model = myLeNet('model1', nb_classes, nb_filters, 40)\n",
        "  preds = model.get_logits(x)\n",
        "  loss = CrossEntropy(model, smoothing=0.1)\n",
        "  print(\"Defined TensorFlow model graph.\")\n",
        "\n",
        "  ###########################################################################\n",
        "  # Training the model using TensorFlow\n",
        "  ###########################################################################\n",
        "\n",
        "  # Train an MNIST model\n",
        "  train_params = {\n",
        "      'nb_epochs': nb_epochs,\n",
        "      'batch_size': batch_size,\n",
        "      'learning_rate': learning_rate\n",
        "  }\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  rng = np.random.RandomState([2020, 12, 15])\n",
        "  train(sess, loss, x_train, y_train, args=train_params, rng=rng)\n",
        "\n",
        "  # Evaluate the accuracy of the MNIST model on legitimate test examples\n",
        "  eval_params = {'batch_size': batch_size}\n",
        "  accuracy = model_eval(sess, x, y, preds, x_test, y_test, args=eval_params)\n",
        "  assert x_test.shape[0] == test_end - test_start, x_test.shape\n",
        "  print('Test accuracy on legitimate test examples: {0}'.format(accuracy))\n",
        "  report.clean_train_clean_eval = accuracy\n",
        "\n",
        "  ###########################################################################\n",
        "  # Craft adversarial examples using the Jacobian-based saliency map approach\n",
        "  ###########################################################################\n",
        "  print('Crafting ' + str(source_samples) + ' * ' + str(nb_classes - 1) +\n",
        "        ' adversarial examples')\n",
        "\n",
        "  # Keep track of success (adversarial example classified in target)\n",
        "  results = np.zeros((nb_classes, source_samples), dtype='i')\n",
        "\n",
        "  # Rate of perturbed features for each test set example and target class\n",
        "  perturbations = np.zeros((nb_classes, source_samples), dtype='f')\n",
        "\n",
        "  # Initialize our array for grid visualization\n",
        "  grid_shape = (nb_classes, nb_classes, img_rows, img_cols, nchannels)\n",
        "  grid_viz_data = np.zeros(grid_shape, dtype='f')\n",
        "\n",
        "  # Instantiate a SaliencyMapMethod attack object\n",
        "  jsma = SaliencyMapMethod(model, sess=sess)\n",
        "  jsma_params = {'theta': 1., 'gamma': 0.1,\n",
        "                 'clip_min': 0., 'clip_max': 1.,\n",
        "                 'y_target': None}\n",
        "\n",
        "  figure = None\n",
        "  # Loop over the samples we want to perturb into adversarial examples\n",
        "  sample_ind = 300\n",
        "  attacked_classes = []\n",
        "  num = 0\n",
        "  while num < 10:\n",
        "    current_class = int(np.argmax(y_test[sample_ind]))\n",
        "    \n",
        "    # If current class is already attacked\n",
        "    if current_class in attacked_classes:\n",
        "      sample_ind += 1\n",
        "      continue\n",
        "    \n",
        "    print('--------------------------------------')\n",
        "    print('Attacking input %i/%i' % (num + 1, source_samples))\n",
        "    attacked_classes.append(current_class)\n",
        "    sample = x_test[sample_ind:(sample_ind + 1)]\n",
        "\n",
        "    # We want to find an adversarial example for each possible target class\n",
        "    # (i.e. all classes that differ from the label given in the dataset)\n",
        "    target_classes = other_classes(nb_classes, current_class)\n",
        "\n",
        "    # For the grid visualization, keep original images along the diagonal\n",
        "    grid_viz_data[current_class, current_class, :, :, :] = np.reshape(\n",
        "        sample, (img_rows, img_cols, nchannels))\n",
        "\n",
        "    # Loop over all target classes\n",
        "    for target in target_classes:\n",
        "      print('Generating adv. example for target class %i' % target)\n",
        "\n",
        "      # This call runs the Jacobian-based saliency map approach\n",
        "      one_hot_target = np.zeros((1, nb_classes), dtype=np.float32)\n",
        "      one_hot_target[0, target] = 1\n",
        "      jsma_params['y_target'] = one_hot_target\n",
        "      adv_x = jsma.generate_np(sample, **jsma_params)\n",
        "\n",
        "      # Check if success was achieved\n",
        "      res = int(model_argmax(sess, x, preds, adv_x) == target)\n",
        "\n",
        "      # Compute number of modified features\n",
        "      adv_x_reshape = adv_x.reshape(-1)\n",
        "      test_in_reshape = x_test[sample_ind].reshape(-1)\n",
        "      nb_changed = np.where(adv_x_reshape != test_in_reshape)[0].shape[0]\n",
        "      percent_perturb = float(nb_changed) / adv_x.reshape(-1).shape[0]\n",
        "\n",
        "      # Display the original and adversarial images side-by-side\n",
        "      if viz_enabled:\n",
        "        figure = pair_visual(\n",
        "            np.reshape(sample, (img_rows, img_cols, nchannels)),\n",
        "            np.reshape(adv_x, (img_rows, img_cols, nchannels)), figure)\n",
        "\n",
        "      # Add our adversarial example to our grid data\n",
        "      grid_viz_data[target, current_class, :, :, :] = np.reshape(\n",
        "          adv_x, (img_rows, img_cols, nchannels))\n",
        "\n",
        "      # Update the arrays for later analysis\n",
        "      results[target, num] = res\n",
        "      perturbations[target, num] = percent_perturb\n",
        "    \n",
        "    num += 1\n",
        "  \n",
        "  print('--------------------------------------')\n",
        "\n",
        "  print('Test accuracy on legitimate test examples: {0}'.format(accuracy))\n",
        "\n",
        "  # Compute the number of adversarial examples that were successfully found\n",
        "  nb_targets_tried = ((nb_classes - 1) * source_samples)\n",
        "  succ_rate = float(np.sum(results)) / nb_targets_tried\n",
        "  print('Avg. rate of successful adv. examples {0:.4f}'.format(succ_rate))\n",
        "  report.clean_train_adv_eval = 1. - succ_rate\n",
        "\n",
        "  # Compute the average distortion introduced by the algorithm\n",
        "  percent_perturbed = np.mean(perturbations[np.where(perturbations!=0)])\n",
        "  print('Avg. rate of perturbed features {0:.4f}'.format(percent_perturbed))\n",
        "\n",
        "  # Compute the average distortion introduced for successful samples only\n",
        "  percent_perturb_succ = np.mean(perturbations[np.where(perturbations!=0)] * (results[np.where(perturbations!=0)] == 1))\n",
        "  print('Avg. rate of perturbed features for successful '\n",
        "        'adversarial examples {0:.4f}'.format(percent_perturb_succ))\n",
        "\n",
        "  # Close TF session\n",
        "  sess.close()\n",
        "\n",
        "  # Finally, block & display a grid of all the adversarial examples\n",
        "  if viz_enabled:\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.close(figure)\n",
        "    _ = grid_visual(grid_viz_data)\n",
        "\n",
        "  return report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLD3P8LmY0Hx"
      },
      "source": [
        "def main(argv=None):\n",
        "  from cleverhans_tutorials import check_installation\n",
        "\n",
        "  mnist_tutorial_jsma(viz_enabled=FLAGS.viz_enabled,\n",
        "                      nb_epochs=FLAGS.nb_epochs,\n",
        "                      batch_size=FLAGS.batch_size,\n",
        "                      source_samples=FLAGS.source_samples,\n",
        "                      learning_rate=FLAGS.learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdXHc3WEY1v5"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  flags.DEFINE_boolean('viz_enabled', VIZ_ENABLED,\n",
        "                       'Visualize adversarial ex.')\n",
        "  flags.DEFINE_integer('nb_epochs', NB_EPOCHS,\n",
        "                       'Number of epochs to train model')\n",
        "  flags.DEFINE_integer('batch_size', BATCH_SIZE, 'Size of training batches')\n",
        "  flags.DEFINE_integer('source_samples', SOURCE_SAMPLES,\n",
        "                       'Nb of test inputs to attack')\n",
        "  flags.DEFINE_float('learning_rate', LEARNING_RATE,\n",
        "                     'Learning rate for training')\n",
        "\n",
        "  tf.app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}